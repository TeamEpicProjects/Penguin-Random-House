{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title          date  rating  \\\n",
      "0                       The Body: A Guide for Occupants  Oct 11, 2019     5.0   \n",
      "1                                     Resistance Reborn  Feb 28, 2020     4.0   \n",
      "2                                  The Book of Two Ways  Jul 13, 2020     4.0   \n",
      "3     How to Write One Song: Loving the Things We Cr...  Feb 21, 2021     4.0   \n",
      "4                                    The Giver of Stars  Sep 08, 2020     4.0   \n",
      "...                                                 ...           ...     ...   \n",
      "8428                                 The Giver of Stars  Feb 12, 2020     5.0   \n",
      "8429        Minor Feelings: An Asian American Reckoning  May 21, 2020     4.0   \n",
      "8430       Trixie and Katya's Guide to Modern Womanhood  Oct 29, 2020     4.0   \n",
      "8431         To Wake the Giant: A Novel of Pearl Harbor  May 22, 2020     4.0   \n",
      "8432                                     Finding Ashley  Apr 14, 2021     4.0   \n",
      "\n",
      "                                                   body  \n",
      "0     Lovingly presented with humour and kindness an...  \n",
      "1      I read through this book quicker than anticip...  \n",
      "2     Jodi Picoult does it again in this new novel. ...  \n",
      "3     I’m a music freak without a shred of musical a...  \n",
      "4     The Giver of Stars by Jojo Moyes won the Book ...  \n",
      "...                                                 ...  \n",
      "8428  I loved this book! Let me start by saying that...  \n",
      "8429  What did i just read?I chose this title becaus...  \n",
      "8430  **3.45 stars ( if we were using a 10/10 scale ...  \n",
      "8431  Thanks to Netgalley, Random House and Ballenti...  \n",
      "8432  Finding Ashley starts with Melissa working har...  \n",
      "\n",
      "[8433 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('goodreads.tsv' , sep='\\t')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>The Giver of Stars</td>\n",
       "      <td>Feb 12, 2020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I loved this book! Let me start by saying that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>Minor Feelings: An Asian American Reckoning</td>\n",
       "      <td>May 21, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>What did i just read?I chose this title becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>Trixie and Katya's Guide to Modern Womanhood</td>\n",
       "      <td>Oct 29, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>**3.45 stars ( if we were using a 10/10 scale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>To Wake the Giant: A Novel of Pearl Harbor</td>\n",
       "      <td>May 22, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Thanks to Netgalley, Random House and Ballenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>Finding Ashley</td>\n",
       "      <td>Apr 14, 2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Finding Ashley starts with Melissa working har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title          date  rating  \\\n",
       "8428                            The Giver of Stars  Feb 12, 2020     5.0   \n",
       "8429   Minor Feelings: An Asian American Reckoning  May 21, 2020     4.0   \n",
       "8430  Trixie and Katya's Guide to Modern Womanhood  Oct 29, 2020     4.0   \n",
       "8431    To Wake the Giant: A Novel of Pearl Harbor  May 22, 2020     4.0   \n",
       "8432                                Finding Ashley  Apr 14, 2021     4.0   \n",
       "\n",
       "                                                   body  \n",
       "8428  I loved this book! Let me start by saying that...  \n",
       "8429  What did i just read?I chose this title becaus...  \n",
       "8430  **3.45 stars ( if we were using a 10/10 scale ...  \n",
       "8431  Thanks to Netgalley, Random House and Ballenti...  \n",
       "8432  Finding Ashley starts with Melissa working har...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.dropna()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parde\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>body</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Body: A Guide for Occupants</td>\n",
       "      <td>Oct 11, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lovingly presented with humour and kindness an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resistance Reborn</td>\n",
       "      <td>Feb 28, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I read through this book quicker than anticip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Book of Two Ways</td>\n",
       "      <td>Jul 13, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jodi Picoult does it again in this new novel. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Write One Song: Loving the Things We Cr...</td>\n",
       "      <td>Feb 21, 2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I’m a music freak without a shred of musical a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Giver of Stars</td>\n",
       "      <td>Sep 08, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Giver of Stars by Jojo Moyes won the Book ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          date  rating  \\\n",
       "0                    The Body: A Guide for Occupants  Oct 11, 2019     5.0   \n",
       "1                                  Resistance Reborn  Feb 28, 2020     4.0   \n",
       "2                               The Book of Two Ways  Jul 13, 2020     4.0   \n",
       "3  How to Write One Song: Loving the Things We Cr...  Feb 21, 2021     4.0   \n",
       "4                                 The Giver of Stars  Sep 08, 2020     4.0   \n",
       "\n",
       "                                                body  sent  \n",
       "0  Lovingly presented with humour and kindness an...     1  \n",
       "1   I read through this book quicker than anticip...     1  \n",
       "2  Jodi Picoult does it again in this new novel. ...     1  \n",
       "3  I’m a music freak without a shred of musical a...     1  \n",
       "4  The Giver of Stars by Jojo Moyes won the Book ...     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(df)-1):\n",
    "    if type(df.iloc[i]['body']) != str:\n",
    "        df.iloc[i]['body'] = str(df.iloc[i]['body'])\n",
    "#function to represent sentiment -1(negetive);0(neutral);1(positive)\n",
    "def sentiment(n):\n",
    "    return 1 if n>=4 else (-1 if n<=2 else 0)\n",
    "#Applying Sentiment Function \n",
    "df['sent'] = df['rating'].apply(sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)    \n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "sentences = list(df['body'])\n",
    "for sen in sentences:\n",
    "    x1.append(clean_text(sen))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parde\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['Review']=x1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0       [lovingly, presented, humour, kindness, great,...\n",
      "1       [read, book, quicker, anticipated, begun, yest...\n",
      "2       [jodi, picoult, new, novel, plane, crash, main...\n",
      "3       [music, freak, without, shred, musical, abilit...\n",
      "4       [giver, stars, jojo, moyes, book, bucket, list...\n",
      "                              ...                        \n",
      "8428    [loved, book, let, start, saying, really, read...\n",
      "8429    [read, chose, title, unenlightened, asian, exp...\n",
      "8430    [stars, using, scale, itd, trixie, katya, real...\n",
      "8431    [thanks, netgalley, random, house, ballentine,...\n",
      "8432    [finding, ashley, starts, melissa, working, ha...\n",
      "Name: Review, Length: 8139, dtype: object \n",
      "\n",
      "Sent\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "8428    1\n",
      "8429    1\n",
      "8430    1\n",
      "8431    1\n",
      "8432    1\n",
      "Name: sent, Length: 8139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df1 = df\n",
    "    x_data = df['Review']       # Reviews/Input\n",
    "    y_data = df['sent']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sent')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "2803    [milly, aubrey, jonah, cousins, really, know, ...\n",
      "5995    [good, book, kind, predictable, areas, less, e...\n",
      "3711    [received, arc, random, house, publishing, gro...\n",
      "4538    [wanting, read, book, since, first, heard, alw...\n",
      "5025    [good, book, desolation, road, really, good, b...\n",
      "                              ...                        \n",
      "2271    [collection, essays, asian, american, resonate...\n",
      "796     [say, second, instalment, aurora, cycle, well,...\n",
      "7508     [stars, think, great, beginners, feminist, book]\n",
      "1812    [stars, simulation, become, indistinguishable,...\n",
      "3412    [stars, aboard, strick, family, dysfunction, t...\n",
      "Name: Review, Length: 6511, dtype: object \n",
      "\n",
      "1983    [holy, shit, book, exquisite, challenge, sooth...\n",
      "4619    [essay, excellent, starting, usually, quick, p...\n",
      "3545    [liked, plot, teenage, girls, sent, convents, ...\n",
      "4292    [thought, provoking, charged, collection, pers...\n",
      "4162                       [overall, underwhelming, read]\n",
      "                              ...                        \n",
      "5082    [hesitant, reading, book, thought, opinion, wh...\n",
      "4540    [today, happy, part, write, reads, ultimate, b...\n",
      "4025    [really, enjoyable, read, family, small, towns...\n",
      "3366    [really, important, topic, youve, ever, listen...\n",
      "3160    [every, single, sentence, book, gold, katerine...\n",
      "Name: Review, Length: 1628, dtype: object \n",
      "\n",
      "Test Set\n",
      "2803    1\n",
      "5995    1\n",
      "3711    1\n",
      "4538    1\n",
      "5025    1\n",
      "       ..\n",
      "2271    1\n",
      "796     0\n",
      "7508    1\n",
      "1812    0\n",
      "3412    0\n",
      "Name: sent, Length: 6511, dtype: int64 \n",
      "\n",
      "1983    1\n",
      "4619    1\n",
      "3545    1\n",
      "4292    0\n",
      "4162    0\n",
      "       ..\n",
      "5082    1\n",
      "4540    1\n",
      "4025    1\n",
      "3366   -1\n",
      "3160    1\n",
      "Name: sent, Length: 1628, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for Review in x_train:\n",
    "        review_length.append(len(Review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[ 733  782  916 ...    0    0    0]\n",
      " [  17    1  143 ...    0    0    0]\n",
      " [ 558  274  622 ...    0    0    0]\n",
      " ...\n",
      " [  69   21   31 ...    0    0    0]\n",
      " [  69 8770  247 ...  696   41    2]\n",
      " [  69 4301 1697 ... 2089 1605 1785]] \n",
      "\n",
      "Encoded X Test\n",
      " [[2650 1567    1 ...    0    0    0]\n",
      " [ 866  377  908 ...   82    0    0]\n",
      " [  98   58 1785 ...    0    0    0]\n",
      " ...\n",
      " [   6  372    3 ...    0    0    0]\n",
      " [   6  240  800 ...    0    0    0]\n",
      " [  61  490 1762 ... 7025  106 4747]] \n",
      "\n",
      "Maximum review length:  82\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 82, 32)            888224    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 913,121\n",
      "Trainable params: 913,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the vocabulary size and then perform padding \n",
    "vocab_size = len(token.word_index) + 1\n",
    "maxlen = 50\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "X_train\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 10s 135ms/step - loss: 0.6786 - accuracy: 0.7017\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.70174, saving model to models\\LSTM.h5\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 7s 144ms/step - loss: 0.6560 - accuracy: 0.6881\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.70174\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 7s 128ms/step - loss: 0.5487 - accuracy: 0.6686\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.70174\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 7s 137ms/step - loss: 0.5629 - accuracy: 0.6663\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.70174\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 7s 131ms/step - loss: 0.3225 - accuracy: 0.7455\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.70174 to 0.74551, saving model to models\\LSTM.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa2fdce148>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction: 1096\n",
      "Wrong Prediction: 532\n",
      "Accuracy: 67.32186732186733\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test, batch_size = 128)\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Review: book is awesome\n"
     ]
    }
   ],
   "source": [
    "review = str(input('Books Review: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned:  book is awesome\n",
      "Filtered:  ['book awesome']\n"
     ]
    }
   ],
   "source": [
    "# Pre-process input\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "print('Cleaned: ', review)\n",
    "\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81.09067]]\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(tokenize_words)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "if result >= 0.7:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
